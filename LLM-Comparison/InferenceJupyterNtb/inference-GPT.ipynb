{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a834b0",
   "metadata": {},
   "source": [
    "This file tests the inference of online GPT4o-mini.\n",
    "You need a paid licence key in order to run this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb361b-6445-4fd6-bc73-9e84919cd1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c66697",
   "metadata": {},
   "source": [
    "IMPORTANT\n",
    "Insert openai API key. This can be recieved from the openAI website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbcd264-1c89-445c-9135-73f1285e2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"Input your openai API key\"\n",
    "modelName = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "112cd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize system prompt\n",
    "systemPrompt = '''\n",
    "Respond as if you are the following character:\n",
    "\n",
    "Your backstory - Once a renowned scientist, however a tragic accident caused you to lose parts of your memory. Now, you are willing to help anyone who is on the quest of saving your village.\n",
    "\n",
    "The world you live in - the edge of a small village surrounded by meadows as far as the eye can see. Your village is in danger, since the only water source - the river next to your house, has been polluted.\n",
    "\n",
    "Your current location - In the middle of the village in front of your house.\n",
    "\n",
    "Your name - Bryn\n",
    "\n",
    "Your personality - Witty, knowledgeable, always ready with a clever remark. Light hearted demeanour.\n",
    "\n",
    "Your secrets - You have the knowledge on how to save the dying river.\n",
    "\n",
    "Your needs - For starters, you are looking for someone to take you to the nearest solar panels. You remember that you left something important there, but you canâ€™t remember what.\n",
    "You do not want to bring this up unless directly asked.\n",
    "\n",
    "And your interests - Deep love for the environment. Loves nature, is fascinated by the ecosystem. You enjoy telling stories about the world and your village.\n",
    "You want to talk about this at all cost.\n",
    "\n",
    "Do not mention you are an AI machine learning model or Open AI. Give only dialogue and only from the first-person perspective. Do not under any circumstances narrate the scene, what you are doing, or what you are saying.\n",
    "Keep responses short. Max 1 small paragraph \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d5a8b",
   "metadata": {},
   "source": [
    "Go through file for all training questions \"single\", send the to the model with a systempt prompt, write down the responses and response times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all single questions \n",
    "inFilename = \"testing-questions-single.md\"\n",
    "outFilename = \"answers-gpt4o-single.md\"\n",
    "with open(inFilename, \"r\") as file:\n",
    "    questions = file.readlines()\n",
    "\n",
    "# initialize response times\n",
    "responseTimes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0422ec8-a9f9-4b9e-9a9c-89080d784513",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outFilename, \"w\") as answersFile:\n",
    "    for question in questions:\n",
    "        question = question.strip()  # Remove any leading/trailing whitespace\n",
    "        \n",
    "        # Message prompt\n",
    "        prompts = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": systemPrompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        startTime = time.time()\n",
    "        \n",
    "        response = openai.chat.completions.create(model = modelName, messages = prompts)\n",
    "\n",
    "        # Process answer\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        \n",
    "        endTime = time.time()\n",
    "        \n",
    "        # Record the response time\n",
    "        responseTime = endTime - startTime\n",
    "        responseTimes.append(responseTime)\n",
    "        \n",
    "        # Write the response to the file\n",
    "        answersFile.write(f\"Q: {question}\\nA: {answer}\\nTime taken: {responseTime:.2f} seconds\\n\\n\")\n",
    "        print(f\"Q: {question}\\nA: {answer}\\nTime taken: {responseTime:.2f} seconds\\n\\n\")\n",
    "        \n",
    "    answersFile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e818723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the time AVG, MAX, MIN in the end of the file\n",
    "averageTime = sum(responseTimes) / len(responseTimes)\n",
    "maxTime = max(responseTimes)\n",
    "minTime = min(responseTimes)\n",
    "\n",
    "with open(outFilename, \"a\") as answersFile:\n",
    "    answersFile.write(f\"\\n\\n----------------------------------------\\n\")\n",
    "    answersFile.write(f\"\\nAverage Time: {averageTime:.2f} seconds\")\n",
    "    answersFile.write(f\"\\nMax Time: {maxTime:.2f} seconds\")\n",
    "    answersFile.write(f\"\\nMin Time: {minTime:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c7859",
   "metadata": {},
   "source": [
    "Go through file of questions - history, feed them to the LLM in a communication style (keeping the history). Measure the times andwrite the results into a second answer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4527624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all communication questions \n",
    "inFilename2 = \"testing-questions-history.md\"\n",
    "outFilename2 = \"answers-gpt4o-history.md\"\n",
    "with open(inFilename2, \"r\") as file:\n",
    "    questions = file.readlines()\n",
    "\n",
    "# initialize response times\n",
    "responseTimes2 = []\n",
    "\n",
    "# init history\n",
    "history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\":systemPrompt\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d2f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outFilename2, \"w\") as answersFile2:\n",
    "    for question in questions:\n",
    "        question = question.strip()  # Remove any leading/trailing whitespace\n",
    "        \n",
    "        # User question\n",
    "        history.append({\"role\": \"user\", \"content\": question})\n",
    "        \n",
    "        startTime = time.time()\n",
    "        \n",
    "        response = openai.chat.completions.create(model = modelName, messages = history)\n",
    "\n",
    "        # Process answer\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        \n",
    "        endTime = time.time()\n",
    "        \n",
    "        # Record the response time\n",
    "        responseTime = endTime - startTime\n",
    "        responseTimes2.append(responseTime)\n",
    "\n",
    "        # Write the response to the file\n",
    "        answersFile2.write(f\"Q: {question}\\nA: {answer}\\nTime taken: {responseTime:.2f} seconds\\n\\n\")\n",
    "        print(f\"Q: {question}\\nA: {answer}\\nTime taken: {responseTime:.2f} seconds\\n\\n\")\n",
    "        \n",
    "\n",
    "        # Add response to history\n",
    "        history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "\n",
    "    answersFile2.flush()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1ccc2-9ae4-4496-bf75-fd1df455e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate statistics\n",
    "averageTime2 = sum(responseTimes2) / len(responseTimes2)\n",
    "maxTime2 = max(responseTimes2)\n",
    "minTime2 = min(responseTimes2)\n",
    "\n",
    "# Write the statistics to the file\n",
    "with open(outFilename2, \"a\") as answersFile2:\n",
    "    answersFile2.write(f\"\\n\\n----------------------------------------\\n\")\n",
    "    answersFile2.write(f\"\\nAverage Time: {averageTime2:.2f} seconds\")\n",
    "    answersFile2.write(f\"\\nMax Time: {maxTime2:.2f} seconds\")\n",
    "    answersFile2.write(f\"\\nMin Time: {minTime2:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
